{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AirstripClassifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPHH+SheqOfgN/msJPP9Fzv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Higgins2718/AirstripClassifier/blob/master/AirstripClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3hM4AGm4fk0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import Model\n",
        "from keras import models\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Load the pretrained InceptionV3 model for transfer learning\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), # Shape of our images\n",
        "                                include_top = False, # Leave out the last fully connected layer\n",
        "                                weights = 'imagenet')\n",
        "\n",
        "x = layers.Flatten()(pre_trained_model.output)\n",
        "\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "\n",
        "x = layers.Dropout(0.2)(x)\n",
        "\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "\n",
        "model = Model(pre_trained_model.input, x)\n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001),\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Bho0dGS5aaI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "4a845178-426f-40de-d5dc-313ee472ec16"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Load the airstrips dataset from Google Drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!ln -s \"/content/drive/My Drive/satellite_airstrips/train/\"/mydrive\n",
        "\n",
        "!mount --bind /content/drive/My\\ Drive /content/mounted_drive/\n",
        "%cd /content/mounted_drive"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "ln: failed to create symbolic link './mydrive': File exists\n",
            "/content/mounted_drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWu7Nq4d5da_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create training and testing datasets\n",
        "\n",
        "import tensorflow as tf\n",
        "directory = '/content/drive/My Drive/satellite_airstrips/'\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "strips = glob(\"/content/mounted_drive/satellite_airstrips/train/landing_strips_4/*.jpg\")\n",
        "not_strips = glob(\"/content/mounted_drive/satellite_airstrips/train/not_landing_strips_4/*.jpg\")\n",
        "\n",
        "strips_train, strips_test = train_test_split(strips, test_size=0.1)\n",
        "not_strips_train, not_strips_test = train_test_split(not_strips, test_size=0.1)\n",
        "\n",
        "TRAIN_DIR = 'train'\n",
        "TEST_DIR = 'test'\n",
        "\n",
        "!mkdir test\n",
        "!mkdir train\n",
        "\n",
        "!mkdir test/strips\n",
        "files = ' '.join(strips_test)\n",
        "!mv -t test/strips $files\n",
        "\n",
        "!mkdir test/not_strips\n",
        "files = ' '.join(not_strips_test)\n",
        "!mv -t test/not_strips $files\n",
        "\n",
        "\n",
        "\n",
        "!mkdir train/strips\n",
        "files = ' '.join(strips_train)\n",
        "!mv -t train/strips $files\n",
        "\n",
        "!mkdir train/not_strips\n",
        "files = ' '.join(not_strips_train)\n",
        "!mv -t train/not_strips $files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlNVqQw85fVH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5e5d41d8-be51-4bdb-f52b-41a00d2bb3e6"
      },
      "source": [
        "# Load images from the training and testing datasets\n",
        "# Add some data augmentation to the images so the model doesn't overfit\n",
        "\n",
        "TRAIN_DIR = '/content/mounted_drive/train'\n",
        "TEST_DIR = '/content/mounted_drive/test'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1.0/255.,\n",
        "                                  horizontal_flip = True,\n",
        "                                  rotation_range = 40)\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(TRAIN_DIR,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary',\n",
        "                                                    target_size = (150, 150))\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(TEST_DIR,\n",
        "                                                        batch_size = 20,\n",
        "                                                        class_mode = 'binary',\n",
        "                                                        target_size = (150, 150), shuffle=False) "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1485 images belonging to 2 classes.\n",
            "Found 166 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbndwfcq5guf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stop training once accuracy hits 99.9%\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.959):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wSgJqXl5i8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add variables for the length of the train and validation data \n",
        "ntrain = 1485\n",
        "nval = 166\n",
        "\n",
        "# We will use a batch size of 32. Note: batch size should be a factor of 2.***4,8,16,32,64...***\n",
        "batch_size = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOH4IHx25mKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "5c6d11cd-3543-4a31-d244-74c66aecb63c"
      },
      "source": [
        "# Train the model\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = ntrain // batch_size,\n",
        "            epochs = 20,\n",
        "            validation_steps = nval // batch_size,\n",
        "            verbose = 2,\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "46/46 - 220s - loss: 0.8383 - acc: 0.7591 - val_loss: 1.6375 - val_acc: 0.6000\n",
            "Epoch 2/20\n",
            "46/46 - 220s - loss: 0.3597 - acc: 0.8751 - val_loss: 1.7541 - val_acc: 0.7000\n",
            "Epoch 3/20\n",
            "46/46 - 221s - loss: 0.2031 - acc: 0.9215 - val_loss: 4.0426 - val_acc: 0.5800\n",
            "Epoch 4/20\n",
            "46/46 - 216s - loss: 0.2992 - acc: 0.9116 - val_loss: 4.3762 - val_acc: 0.4300\n",
            "Epoch 5/20\n",
            "46/46 - 218s - loss: 0.1734 - acc: 0.9293 - val_loss: 1.4525 - val_acc: 0.8500\n",
            "Epoch 6/20\n",
            "46/46 - 220s - loss: 0.2163 - acc: 0.9293 - val_loss: 0.8861 - val_acc: 0.8800\n",
            "Epoch 7/20\n",
            "46/46 - 215s - loss: 0.1807 - acc: 0.9525 - val_loss: 0.9009 - val_acc: 0.9300\n",
            "Epoch 8/20\n",
            "46/46 - 221s - loss: 0.2179 - acc: 0.9326 - val_loss: 0.4791 - val_acc: 0.9100\n",
            "Epoch 9/20\n",
            "46/46 - 229s - loss: 0.1517 - acc: 0.9467 - val_loss: 0.5682 - val_acc: 0.9600\n",
            "Epoch 10/20\n",
            "46/46 - 220s - loss: 0.1404 - acc: 0.9558 - val_loss: 0.3570 - val_acc: 0.9200\n",
            "Epoch 11/20\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "46/46 - 223s - loss: 0.1098 - acc: 0.9691 - val_loss: 0.8725 - val_acc: 0.9100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bzut_EAUtlM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c88d2cd0-3ad6-4cc7-de59-396c012579ab"
      },
      "source": [
        "# Check the model's accuracy on the test dataset\n",
        "\n",
        "test_loss, test_acc = model.evaluate_generator(validation_generator)\n",
        "print('test acc:', test_acc)\n",
        "print('test loss:', test_loss)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test acc: 0.9216867685317993\n",
            "test loss: 0.6053807735443115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHGzd74zU_5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the model\n",
        "\n",
        "model.save_weights('airstrip_classifier_weights.h5')\n",
        "model.save('airstrip_classifier.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1uSHr-s5-tA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "02adbe2a-1a9a-4207-9831-d8e334a4bf00"
      },
      "source": [
        "# Get a list of all misclassified images in our test dataset\n",
        "predicted = model.predict(validation_generator)\n",
        "indices = [i for i,v in enumerate(predicted) if round(predicted[i][0])!=validation_generator.classes[i]]\n",
        "misclassified_imgs = []\n",
        "for index, file in enumerate(validation_generator.filenames):\n",
        "  if index in indices:\n",
        "    print(file)\n",
        "    misclassified_imgs.append(file)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "not_strips/36.357900596421864-116.59087616284064.jpg\n",
            "not_strips/38.93265314899398-99.2073882340789.jpg\n",
            "not_strips/42.1122281328539-90.40852258117864.jpg\n",
            "not_strips/42.81556639125244-90.19088212023023.jpg\n",
            "not_strips/43.013831842124134-83.32170289828017.jpg\n",
            "not_strips/44.74780260391893-87.70133392734365.jpg\n",
            "not_strips/48.05621824809539-73.16933115096072.jpg\n",
            "strips/0A2DC496-F49E-426F-9709-E9C2AFE5345E.jpg\n",
            "strips/3CD1E697-7E62-40B0-8944-5B4D06183F75.jpg\n",
            "strips/5DFA7A4A-4449-4D28-AD94-3656445CCC66.jpg\n",
            "strips/AB9D6CBA-1B2A-4794-B959-46EA5D13BD38.jpg\n",
            "strips/AD75D47E-FD77-42D9-B2CE-CCECFBB4F12B.jpg\n",
            "strips/C0E1D327-86A0-4D6A-BC65-20B6816BFFDE.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZi-TYW06Ibe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# View the misclassified images inline\n",
        "\n",
        "for img in misclassified_imgs:\n",
        "  plt.figure()\n",
        "  plt.imshow(cv2.imread('/content/mounted_drive/test/'+img))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlWZB2kQ8Oo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.resnet import ResNet50\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "\n",
        "# Load pretrained Resnet weights\n",
        "resnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "# Initialize a new model and add the pretrained Resnet layers on top of it\n",
        "# Exclude the final layer of the resnet model so that outputs are not 'activated'\n",
        "# The result will be the a vector embedding for the inputted image \n",
        "my_new_model = Sequential()\n",
        "my_new_model.add(ResNet50(include_top=False, pooling='avg', weights='imagenet'))\n",
        "\n",
        "# Say not to train first layer (ResNet) model. It is already trained\n",
        "my_new_model.layers[0].trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f89j8DsK8R1T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "548e91d8-fc61-48a6-90db-4c0c5ba1cc57"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "\n",
        "# Get the Imagnet vector embeddings for all images in a directory\n",
        "def extract_vectors(path):\n",
        "    resnet_feature_list = []\n",
        "\n",
        "    for im in glob.glob(path+'*.jpg'):\n",
        "        \n",
        "        im = cv2.imread(im)\n",
        "        im = cv2.resize(im,(224,224))\n",
        "        img = preprocess_input(np.expand_dims(im.copy(), axis=0))\n",
        "        resnet_feature = my_new_model.predict(img)\n",
        "        resnet_feature_np = np.array(resnet_feature)\n",
        "        resnet_feature_list.append(resnet_feature_np.flatten())\n",
        "\n",
        "    return np.array(resnet_feature_list)\n",
        "\n",
        "# Get the Imagenet vector embeddings for a list of images\n",
        "def extract_vectors_from_list(imgs):\n",
        "    resnet_feature_list = []\n",
        "\n",
        "    for im in imgs:\n",
        "        \n",
        "        im = cv2.imread(im)\n",
        "        im = cv2.resize(im,(224,224))\n",
        "        img = preprocess_input(np.expand_dims(im.copy(), axis=0))\n",
        "        resnet_feature = my_new_model.predict(img)\n",
        "        resnet_feature_np = np.array(resnet_feature)\n",
        "        resnet_feature_list.append(resnet_feature_np.flatten())\n",
        "\n",
        "    return np.array(resnet_feature_list)\n",
        "\n",
        "# Get the Imagenet vector embedding for a single image\n",
        "def extract_one_vector(path):\n",
        "    resnet_feature_list = []\n",
        "\n",
        "   \n",
        "    im = cv2.imread(path)\n",
        "    print(im.shape)\n",
        "    im = cv2.resize(im,(224,224))\n",
        "    img = preprocess_input(np.expand_dims(im.copy(), axis=0))\n",
        "    resnet_feature = my_new_model.predict(img)\n",
        "    resnet_feature_np = np.array(resnet_feature)\n",
        "    resnet_feature_list.append(resnet_feature_np.flatten())\n",
        "\n",
        "    return np.array(resnet_feature_list)\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Find images that are semantically similar to a list of images\n",
        "# Receives a list of images and their directory \n",
        "def get_similar_images(img_index, source):\n",
        "    vector = extract_one_vector(img_index)\n",
        "    cosine_similarities = []\n",
        "    \n",
        "    cos = cosine_similarity(vector, source)\n",
        "\n",
        "    similar = np.argsort(-cos, axis=-1, kind='quicksort', order=None)[:,0:25] \n",
        "\n",
        "    return similar\n",
        "\n",
        "# Display a list of images inline, given their indices and their directory\n",
        "def show_images(index_array, directory):\n",
        "  for index_list in index_array:\n",
        "    for img_index in index_list:\n",
        "      plt.figure()\n",
        "      #print(directory+os.listdir(directory)[img_index])\n",
        "      plt.imshow(cv2.imread(directory+os.listdir(directory)[img_index]))\n",
        "\n",
        "# Return the paths of all images in a directory, given their indices\n",
        "def get_paths(index_array, directory):\n",
        "  img_paths = [ ]\n",
        "  for index_list in index_array:\n",
        "    for img_index in index_list:\n",
        "      img_paths.append(directory+os.listdir(directory)[img_index])\n",
        "\n",
        "  return img_paths\n",
        "\n",
        "# Given a cluster, return all labels belonging to it\n",
        "def cluster_indices(clust_num, labels_array): \n",
        "    return np.where(labels_array == clust_num)[0]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCDkH4ND7rUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "def similar_to_errors(error_image_directory, category):\n",
        "  errors = extract_vectors_from_list(error_image_directory)\n",
        "  kmeans = KMeans(n_clusters=4, random_state=0).fit(errors)\n",
        "  print(kmeans.labels_)\n",
        "  # for each cluster, get the most representative item\n",
        "  if category == 'nstrips':\n",
        "    closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, nstrips_errors)\n",
        "  else:\n",
        "    closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, strips_errors)\n",
        "\n",
        "  \n",
        "  cluster_0 = error_image_directory[closest[0]]\n",
        "  cluster_1 = error_image_directory[closest[1]]\n",
        "  cluster_2 = error_image_directory[closest[2]]\n",
        "  cluster_3 = error_image_directory[closest[3]]\n",
        "\n",
        "  clusters = [cluster_0, cluster_1, \n",
        "                    cluster_2, cluster_3]\n",
        "  paths_list = []\n",
        "\n",
        "  for cluster in clusters:\n",
        "    print(cluster)\n",
        "    if category == 'nstrips':\n",
        "      arrays = get_similar_images(cluster, not_airstrip_vectors)\n",
        "      paths = get_paths(arrays, '/content/mounted_drive/satellite_airstrips/index/')\n",
        "\n",
        "    else:\n",
        "      arrays = get_similar_images(cluster, airstrip_vectors)\n",
        "      paths = get_paths(arrays, '/content/mounted_drive/satellite_airstrips/extra_airstrips/')\n",
        "      #paths = get_paths(arrays, '/content/mounted_drive/satellite_airstrips/train/landing_strips_4/')\n",
        "\n",
        "    paths_list.append(paths)\n",
        "    #return clusters\n",
        "    paths_list = [item for sublist in paths_list for item in sublist]\n",
        "\n",
        "    return paths_list\n",
        "\n",
        "#clusters = similar_to_errors(misclassified_strips, 'strips')\n",
        "#new_airstrip_paths = similar_to_errors(misclassified_strips, 'strips')\n",
        "#new_n_airstrip_paths = similar_to_errors(nstrips_errors_dir, 'nstrips')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXExXbPb7--S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}